{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('C:\\AnacondaSrc\\Course2\\week1\\dvertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = adver_data[['TV','Radio','Newspaper']].values\n",
    "y = adver_data['Sales'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means, stds = np.mean(X,axis=0), np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = (X - means)/stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.hstack((X,np.ones((X.shape[0],1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9]\n28.34575\n"
     ]
    }
   ],
   "source": [
    "def mserror(y, y_pred):\n",
    "    # Ваш код здесь\n",
    "    return (1./ y.size)*np.sum((y_pred - y)**2)\n",
    "\n",
    "temp= np.median(y)\n",
    "\n",
    "ymedian = [temp for i in y]\n",
    "print ymedian\n",
    "print mserror(y, ymedian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(y, ymedian)\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, \"1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.91925365   2.79206274  -0.02253861  14.0225    ]\n"
     ]
    }
   ],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.dot( np.linalg.pinv(X), y)\n",
    "\n",
    "t= np.linalg.pinv(X)\n",
    "t= normal_equation(X, y)\n",
    "y.shape\n",
    "t.shape\n",
    "print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.91925365   2.79206274  -0.02253861  14.0225    ]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.dot([0., 0., 0., 1.], norm_eq_weights)\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y, linear_prediction(X, norm_eq_weights))\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n[ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print np.dot(np.ones([5]), np.ones([5]))\n",
    "print np.ones([5]) * np.ones([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    dif = w[0]*X[train_ind,0]+w[1]*X[train_ind,1]+w[2]*X[train_ind,2]+w[3]*X[train_ind,3]-y[train_ind]\n",
    "    grad0 = dif*2./4.*X[train_ind,0]\n",
    "    grad1 = dif*2./4.*X[train_ind,1]\n",
    "    grad2 = dif*2./4.*X[train_ind,2]\n",
    "    grad3 = dif*2./4.*X[train_ind,3]\n",
    "    print dif\n",
    "    print len(y)\n",
    "    print np.array([grad0, grad1, grad2, grad3])    \n",
    "    return w - eta * np.array([grad0, grad1, grad2, grad3])\n",
    "def stochastic_gradient_step1(X, y, w, train_ind, eta=0.01):\n",
    "    # признаки объекта, на котором будем улучшать значение функционала ошибки\n",
    "    x = X[train_ind,:]\n",
    "\n",
    "    #отклонение на объекте\n",
    "    delta = np.dot(x,w) - y[train_ind]\n",
    "    print delta\n",
    "    # число объектов в тренировочной выборке\n",
    "    l = float(len(y))\n",
    "    \n",
    "    # вычислим вектор градиента по формуле (2/l) * (x.T) * <вектор отклонения> \n",
    "    grad = x*delta*2/l\n",
    "    print grad\n",
    "    # возвращаем новые веса\n",
    "    return  w-eta*grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.]\n-14.8\n200\n[-11.5059924    6.57771309   3.11817664  -7.4       ]\n[ 0.11505992 -0.06577713 -0.03118177  0.074     ]\n-12.4235615418\n200\n[-1.34605349  5.56347276  3.70406073 -6.21178077]\n[ 0.12852046 -0.12141186 -0.06822237  0.13611781]\n-19.3310934152\n200\n[ -7.97464614  -6.68054716 -12.65626953  -9.66554671]\n[ 0.20826692 -0.05460639  0.05834032  0.23277327]\n-18.622517801\n200\n[-6.20365834 -6.05843603 -6.62037391 -9.3112589 ]\n[ 0.2703035   0.00597797  0.12454406  0.32588586]\n-7.26916338002\n200\n[ 5.17955275  3.0098296   0.14287965 -3.63458169]\n[ 0.21850798 -0.02412032  0.12311526  0.36223168]\n-12.1116980089\n200\n[ 2.6335441   3.66549152 -0.31946092 -6.055849  ]\n[ 0.19217254 -0.06077524  0.12630987  0.42279017]\n-15.2831015098\n200\n[-12.39910176   4.83168085   9.44601372  -7.64155075]\n[ 0.31616355 -0.10909205  0.03184974  0.49920568]\n-17.2365387668\n200\n[-7.18102471 -2.58146913 -9.06334106 -8.61826938]\n[ 0.3879738  -0.08327736  0.12248315  0.58538837]\n-13.5889529719\n200\n[-10.56448578   6.03947526   2.86302403  -6.79447649]\n[ 0.49361866 -0.14367211  0.09385291  0.65333314]\n-6.98493513914\n200\n[ 5.22987234  0.36882849 -3.19053457 -3.49246757]\n10\n0.0706147574582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.44131993, -0.14736039,  0.12575825,  0.68825781]),\n array([ 223.71625   ,  221.19694552,  219.8003337 ,  215.78311148,\n         212.24348673,  211.8255391 ,  210.59015565,  208.07742495,\n         204.85832509,  202.7010415 ]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "     # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    \n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        if verbose:\n",
    "            print w\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        w1 = stochastic_gradient_step(X, y, w, random_ind, eta)    \n",
    "        errors = np.append(errors,[0])\n",
    "        errors[iter_num] =  mserror(y, linear_prediction(X,w))\n",
    "        iter_num = iter_num+1\n",
    "        weight_dist =  euclidean(w1,w) \n",
    "        w = w1 \n",
    "        \n",
    "    print iter_num\n",
    "    print weight_dist\n",
    "    return w, errors\n",
    "\n",
    "stochastic_gradient_descent(X, y, np.zeros(4), eta=1e-2, max_iter=10,min_weight_dist=1e-8, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.]\n-14.8\n[-0.23011985  0.13155426  0.06236353 -0.148     ]\n[ 0.0023012  -0.00131554 -0.00062364  0.00148   ]\n-12.5964712308\n[-0.02729575  0.11281809  0.07511227 -0.12596471]\n[ 0.00257416 -0.00244372 -0.00137476  0.00273965]\n-19.3986256905\n[-0.1600501  -0.13407771 -0.25400967 -0.19398626]\n[ 0.00417466 -0.00110295  0.00116534  0.00467951]\n-18.9924281861\n[-0.12653771 -0.12357557 -0.13503757 -0.18992428]\n[ 0.00544003  0.00013281  0.00251571  0.00657875]\n-7.20138258218\n[ 0.10262513  0.05963529  0.00283095 -0.07201383]\n[ 0.00441378 -0.00046354  0.0024874   0.00729889]\n-12.394208767\n[ 0.05389945  0.07501981 -0.00653825 -0.12394209]\n[ 0.00387479 -0.00121374  0.00255279  0.00853831]\n-15.8875626574\n[-0.25778996  0.10045557  0.19639225 -0.15887563]\n[ 0.00645269 -0.0022183   0.00058886  0.01012707]\n-17.984541522\n[-0.1498531  -0.05386991 -0.18913314 -0.17984542]\n[ 0.00795122 -0.0016796   0.0024802   0.01192552]\n-14.7752635468\n[-0.22973523  0.13133438  0.0622593  -0.14775264]\n[ 0.01024857 -0.00299294  0.0018576   0.01340305]\n-6.99993081601\n[ 0.104822    0.00739241 -0.06394768 -0.06999931]\n10\n0.00141532714893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.00920035, -0.00306687,  0.00249708,  0.01410304]),\n array([ 223.71625   ,  223.665389  ,  223.63640485,  223.5549101 ,\n         223.48076245,  223.47256427,  223.44655232,  223.39175145,\n         223.32145218,  223.27074621]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_gradient_descent(X, y, np.zeros(4), eta=1e-2, max_iter=10,min_weight_dist=1e-8, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n0.0333105190373\nWall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, y, np.zeros(4), \n",
    "                                                                            eta=1e-2, max_iter=1e5,\n",
    "                                                                            min_weight_dist=1e-8, seed=42, \n",
    "                                                                            verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xc662a90>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCikgRESkQv8fpLXYqdCcajIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6857b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xce2f780>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMw6ckiYmVlHDgkzM+vo/wN10r6hsmvapgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbc3c2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.93301245,   2.92291325,   0.05091929,  14.00550601])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8084609825540308"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.81424147958\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror(y, linear_prediction(X,stoch_grad_desc_weights))\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}